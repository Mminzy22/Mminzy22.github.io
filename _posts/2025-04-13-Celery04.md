---
title: "Celery 멀티 큐 구성과 워커 분리 전략"
author: mminzy22
date: 2025-04-14 22:00:00 +0900
categories: [Celery]
tags: [TIL, Celery, Django, 멀티큐, 워커분리, 비동기처리]
description: "Django/DRF 기반 Celery 프로젝트에서 멀티 큐를 구성하고, 워커를 역할별로 분리하여 운영 효율성과 장애 대응력을 높이는 방법을 소개합니다."
pin: false
mermaid: true
---


Celery로 다양한 Task를 운영하다 보면, 작업의 성격과 우선순위가 달라지는 상황이 생깁니다. 예를 들어:

- 사용자 알림 이메일 전송은 빠르게 처리되어야 함
- 대용량 데이터 분석은 시간이 오래 걸리므로 별도로 실행되어야 함

이럴 때 **멀티 큐(Multiple Queues)** 구성과 **워커 분리(Worker Segmentation)** 전략을 도입하면 효율적인 운영이 가능합니다.


## 1. 큐 설정하기 (settings.py)

```python
CELERY_TASK_QUEUES = {
    "default": {},
    "emails": {
        "exchange": "emails",
        "routing_key": "emails",
    },
    "heavy": {
        "exchange": "heavy",
        "routing_key": "heavy",
    },
}
```


## 2. Task에 큐 지정하기

```python
@shared_task(queue="emails")
def send_verification_email(user_id):
    ...

@shared_task(queue="heavy")
def generate_large_report():
    ...
```

- `queue` 파라미터로 작업을 분류할 수 있습니다.


## 3. 워커 분리 실행 예시

```bash
# 이메일 관련 워커
celery -A config worker -Q emails --loglevel=info

# 무거운 분석 작업 전용 워커
celery -A config worker -Q heavy --concurrency=2 --loglevel=info

# 기본 큐용 워커
celery -A config worker -Q default --loglevel=info
```

- 서로 다른 큐를 별도 워커로 실행하면, 하나의 작업이 전체 시스템을 점유하는 상황을 막을 수 있습니다.


## 4. use_case 예시: DRF + Celery 멀티 큐 활용

- 회원가입 → 이메일 인증 → `emails` 큐로 발송
- 백오피스에서 정책 통계 리포트 요청 → `heavy` 큐로 전달
- 일반 사용자 요청 → 기본 `default` 큐에서 처리

이렇게 분리하면 각 업무 유형에 맞는 워커에서 작업을 병렬로 처리할 수 있습니다.


## 5. 큐별로 timeout, retry 정책 분리도 가능

```python
@shared_task(bind=True, queue="heavy", soft_time_limit=300, max_retries=2)
def slow_task(self):
    try:
        ...  # 오래 걸리는 작업
    except Exception as e:
        raise self.retry(exc=e, countdown=60)
```

- 무거운 작업에만 제한 조건을 별도로 걸어 안정성 확보
