---
title: "LangChain으로 구현한 면접 챗봇의 대화 흐름 구조"
author: mminzy22
date: 2025-02-24 21:00:00 +0900
categories: [프로젝트, Streamlit, AI]
tags: [Bootcamp, TIL, Chatbot, Streamlit, LangChain, RAG, Pinecone, 프로젝트]
description: "개발자 면접 챗봇에서 LangChain을 활용한 질문 생성과 답변 피드백 흐름을 살펴봅니다. Prompt Template, Retriever, Memory 등 LangChain 요소들을 어떻게 조합했는지 정리합니다."
pin: false
---


## 1. langchain_chatbot.py의 역할

LangChain은 LLM 기반 응용 기능을 빠르게 구성할 수 있게 도와주는 Python 라이브러리입니다. 이 프로젝트에서 LangChain은 주어진 문서를 기반으로 면접 질문을 생성하고, 사용자의 답변에 대해 피드백을 생성하는 역할을 합니다.

LangChain이 구현된 파일은 `backend/langchain_chatbot.py`이며, 전체 구조는 **RAG (Retrieval-Augmented Generation)** 방식으로 설계되어 있습니다.

```
사용자 질문 입력 → Pinecone에서 유사 문서 검색 → GPT가 답변 생성 (피드백) → 사용자에게 출력
```

이때 다음과 같은 구성 요소들이 활용됩니다:
- **Prompt Template**: 답변 피드백을 유도하는 지시문
- **Retriever**: 유사 문서 검색 (Pinecone)
- **Memory**: 대화 흐름 기억
- **LLM + QA Chain**: 최종 답변 생성


## 2. Prompt Template 구성

LangChain의 `PromptTemplate`을 사용해 GPT 모델이 따라야 할 피드백 형식을 명확히 정의했습니다.

```python
prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
    다음은 면접 질문에 대한 사용자 답변입니다:
    질문: {question}
    답변: {context}

    이 답변에 대해 피드백을 주세요. 부족한 부분이나 보완할 점이 있다면 구체적으로 설명해주세요.
    """
)
```

이 구조는 단순히 질문에 답하는 것이 아니라, **답변의 질을 평가하고 개선 방향을 제시하는** 데 초점을 둡니다.


## 3. Retriever 구성 (Pinecone 기반)

벡터 DB인 Pinecone에 저장된 문서에서 질문과 관련된 정보를 검색해 답변 품질을 높입니다.

```python
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3},
)
```

- `as_retriever()`로 LangChain에서 사용할 수 있는 검색기 형태로 변환
- `k=3`: 유사한 문서 3개를 기반으로 답변 생성


## 4. Memory 구조 구성

LangChain의 `ConversationBufferMemory`를 사용하여 사용자와 챗봇의 대화 내역을 유지합니다.

```python
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
)
```

- 이전 대화를 기억해 **연속된 맥락을 유지**
- 추후 multi-turn 피드백 시스템 확장 시 기반으로 활용 가능


## 5. QA 체인 구성 및 실행 흐름

이 모든 구성 요소를 `RetrievalQA` 체인으로 묶어 실제 실행을 담당합니다.

```python
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-3.5-turbo"),
    chain_type="stuff",
    retriever=retriever,
    memory=memory,
    chain_type_kwargs={"prompt": prompt_template},
)

response = qa_chain.run(question)
```

- `stuff` 체인은 검색된 문서를 하나의 입력으로 합쳐 GPT에 전달
- `ChatOpenAI`로 OpenAI GPT 모델 사용
- prompt + memory + retriever가 하나의 체인에서 작동


## 6. 마무리

이번 글에서는 LangChain을 통해 **사용자 질문 → 문서 검색 → 답변 평가 → 응답 출력**까지의 흐름을 정리했습니다. LangChain이 제공하는 abstraction 덕분에 다양한 구성 요소들을 적절히 조합해 Streamlit UI 위에서 작동 가능한 실시간 면접 피드백 챗봇을 만들 수 있었습니다.

